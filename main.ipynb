{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
      "0    Male  67.0             0              1          Yes        Private   \n",
      "1  Female  61.0             0              0          Yes  Self-employed   \n",
      "2    Male  80.0             0              1          Yes        Private   \n",
      "3  Female  49.0             0              0          Yes        Private   \n",
      "4  Female  79.0             1              0          Yes  Self-employed   \n",
      "\n",
      "  Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
      "0          Urban             228.69  36.6  formerly smoked       1  \n",
      "1          Rural             202.21   NaN     never smoked       1  \n",
      "2          Rural             105.92  32.5     never smoked       1  \n",
      "3          Urban             171.23  34.4           smokes       1  \n",
      "4          Rural             174.12  24.0     never smoked       1  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\n",
    "\n",
    "df = df.drop([\"id\"], axis=1)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Data prepocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation data to numerical values\n",
    "\n",
    "First of all, we need to transform every non-numerical data into numerical values. It will concern the columns *gender*, *ever_married*, *work_type*, *Residence_type*, *smoking_status*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female    2994\n",
      "Male      2115\n",
      "Other        1\n",
      "Name: gender, dtype: int64\n",
      "2    2994\n",
      "1    2115\n",
      "0       1\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"gender\"].value_counts())\n",
    "\n",
    "gender_type_map = {\"Female\": 2, \"Male\": 1, \"Other\": 0}\n",
    "df[\"gender\"] = df[\"gender\"].map(gender_type_map)\n",
    "\n",
    "print(df[\"gender\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Private          2925\n",
      "Self-employed     819\n",
      "children          687\n",
      "Govt_job          657\n",
      "Never_worked       22\n",
      "Name: work_type, dtype: int64\n",
      "4    2925\n",
      "3     819\n",
      "2     687\n",
      "1     657\n",
      "0      22\n",
      "Name: work_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"work_type\"].value_counts())\n",
    "\n",
    "work_type_map = {\"Private\": 4, \"Self-employed\": 3, \"children\": 2, \"Govt_job\": 1, \"Never_worked\": 0}\n",
    "df[\"work_type\"] = df[\"work_type\"].map(work_type_map)\n",
    "\n",
    "print(df[\"work_type\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urban    2596\n",
      "Rural    2514\n",
      "Name: Residence_type, dtype: int64\n",
      "1    2596\n",
      "0    2514\n",
      "Name: Residence_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Residence_type\"].value_counts())\n",
    "\n",
    "residence_type_map = {\"Urban\":1, \"Rural\":0}\n",
    "df[\"Residence_type\"] = df[\"Residence_type\"].map(residence_type_map)\n",
    "\n",
    "print(df[\"Residence_type\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes    3353\n",
      "No     1757\n",
      "Name: ever_married, dtype: int64\n",
      "1    3353\n",
      "0    1757\n",
      "Name: ever_married, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"ever_married\"].value_counts())\n",
    "\n",
    "married_type_map = {\"Yes\":1, \"No\":0}\n",
    "df[\"ever_married\"] = df[\"ever_married\"].map(married_type_map)\n",
    "\n",
    "print(df[\"ever_married\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never smoked       1892\n",
      "Unknown            1544\n",
      "formerly smoked     885\n",
      "smokes              789\n",
      "Name: smoking_status, dtype: int64\n",
      "1    1892\n",
      "0    1544\n",
      "2     885\n",
      "3     789\n",
      "Name: smoking_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"smoking_status\"].value_counts())\n",
    "\n",
    "smoking_type_map = {\"smokes\": 3, \"formerly smoked\": 2, \"never smoked\": 1, \"Unknown\": 0}\n",
    "df[\"smoking_status\"] = df[\"smoking_status\"].map(smoking_type_map)\n",
    "\n",
    "print(df[\"smoking_status\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping NaN values\n",
    "\n",
    "We saw ealier that the column *bmi* contains NaN values. So we will simply remove the rows containing this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4700\n",
      "1     209\n",
      "Name: stroke, dtype: int64\n",
      "0    0.957425\n",
      "1    0.042575\n",
      "Name: stroke, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"stroke\"].value_counts())\n",
    "print(df[\"stroke\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the dataset is imbalanced, with only 4% of of data representing a stroke. The risk of having an imbalanced dataset is that the model will probably overfit on the domimant class, here the class 0 (not a stroke).\n",
    "The model can still have a high accuracy but still be completely incorrect.\n",
    "Since the goal of our model is to predict if a stroke will happen, the most important metric to look at isn't the accuracy but the recall of the class 1. We want our model to predict the most stroke possible.\n",
    "\n",
    "If we try to use our current data in a logistic regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[929   0]\n",
      " [ 53   0]]\n",
      "Accuracy:  0.9460285132382892\n",
      "Precision:  1.0\n",
      "Recall:  0.0\n",
      "F1 Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "df_copy = copy.deepcopy(df)\n",
    "\n",
    "labels = df_copy[\"stroke\"]\n",
    "# features = df.drop([\"stroke\", \"Residence_type\", \"gender\"], axis=1)\n",
    "features = df_copy.drop(\"stroke\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "logistic_regression = LogisticRegression(max_iter=400)\n",
    "\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, zero_division=1))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, zero_division=1))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted, even tought the accuracy score is high, the model is completely false because it only predicted data to be of class 0, which means it detected 0 strokes. \n",
    "This is a critical error that we need to fix by balancing the data.\n",
    "\n",
    "Here, we will use up-sampling to even the number of features in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = df[df[\"stroke\"]==0]\n",
    "df_minority = df[df[\"stroke\"]==1]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,\n",
    "                                 n_samples=4700,\n",
    "                                 random_state=123)\n",
    "\n",
    "df = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4700\n",
      "1    4700\n",
      "Name: stroke, dtype: int64\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: stroke, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "labels = df[\"stroke\"]\n",
    "# features = df.drop([\"stroke\", \"Residence_type\", \"gender\"], axis=1)\n",
    "features = df.drop(\"stroke\", axis=1)\n",
    "\n",
    "print(labels.value_counts())\n",
    "print(labels.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
      "249       1   3.0             0              0             0          2   \n",
      "250       1  58.0             1              0             1          4   \n",
      "251       2   8.0             0              0             0          4   \n",
      "252       2  70.0             0              0             1          4   \n",
      "253       1  14.0             0              0             0          0   \n",
      "\n",
      "     Residence_type  avg_glucose_level   bmi  smoking_status  \n",
      "249               0              95.12  18.0               0  \n",
      "250               1              87.96  39.2               1  \n",
      "251               1             110.89  17.6               0  \n",
      "252               0              69.04  35.9               2  \n",
      "253               0             161.28  19.1               0  \n"
     ]
    }
   ],
   "source": [
    "print(features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix = df.corr()\n",
    "# sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test, y_pred):\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Accuracy: \", round(accuracy_score(y_test, y_pred), 3))\n",
    "    print(\"Precision: \", round(precision_score(y_test, y_pred, zero_division=1), 3))\n",
    "    print(\"Recall: \", round(recall_score(y_test, y_pred, zero_division=1), 3))\n",
    "    print(\"F1 Score: \", round(f1_score(y_test, y_pred), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[691 235]\n",
      " [181 773]]\n",
      "Accuracy:  0.779\n",
      "Precision:  0.767\n",
      "Recall:  0.81\n",
      "F1 Score:  0.788\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=400)\n",
    "\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "acc = logistic_regression.score(X_test, y_test)\n",
    "\n",
    "print_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[795 131]\n",
      " [  0 954]]\n",
      "Accuracy:  0.93\n",
      "Precision:  0.879\n",
      "Recall:  1.0\n",
      "F1 Score:  0.936\n"
     ]
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors = 7)\n",
    "\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "acc = knn_classifier.score(X_test, y_test)\n",
    "\n",
    "print_metrics(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('healthcare-stroke-prediction-fu-Cbw5V-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4696ca6e2399baf76289359bbce7f3ba67aa9b0dc385bd7835b24212c371c0a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
